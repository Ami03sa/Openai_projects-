{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ami03sa/Openai_projects-/blob/pdf_rag_system/Speak_with_any_PDF_file_PDF_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pdf ai machine using RAG\n"
      ],
      "metadata": {
        "id": "vUehOJlORE-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Libraries import"
      ],
      "metadata": {
        "id": "NDlbXftjSHdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTBw517ySLF2",
        "outputId": "d488b711-2701-4400-979f-5bbe9d96727c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.101.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_EmMwxN9LBg",
        "outputId": "5cdfdefd-2e90-4ef6-bf86-94804d0753a0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2SWrdmf20GY",
        "outputId": "1bb623d5-d630-471b-aeb9-111a21295678"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.12/dist-packages (7.3.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2025.8.3)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from pinecone) (1.8.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from pinecone) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.5.0)\n",
            "Requirement already satisfied: packaging<25.0,>=24.2 in /usr/local/lib/python3.12/dist-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lYFNyycCQ2p-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import PyPDF2\n",
        "import random\n",
        "import pinecone\n",
        "\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Working with PDF files\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1400/1*FWwgOvUE660a04zoQplS7A.png)\n",
        "\n",
        "\n",
        "\n",
        "### 3.1 Setting up API Key"
      ],
      "metadata": {
        "id": "TwaQS_nXSQxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "btc16h6ySPFA"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Loading a PDF file\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wwNqZjc2th6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load a random PDF from a given directory\n",
        "def load_pdf(file_name):\n",
        "    # Read the PDF file\n",
        "    pdf_file = open(file_name, 'rb')\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "    text_content = \"\"\n",
        "    # Extract text from each page\n",
        "    for page in range(len(pdf_reader.pages)):\n",
        "        text_content += pdf_reader.pages[page].extract_text()\n",
        "\n",
        "    pdf_file.close()\n",
        "\n",
        "    return text_content"
      ],
      "metadata": {
        "id": "hV1ASHAHvm-G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to chunk text by number of words or characters with a given size and overlap\n",
        "def chunk_text(text, chunk_size=1500, chunk_overlap=100, by='word'):\n",
        "    if by not in ['word', 'char']:\n",
        "        raise ValueError(\"Invalid value for 'by'. Use 'word' or 'char'.\")\n",
        "\n",
        "    chunks = []\n",
        "    if by == 'word':\n",
        "        text = text.split()\n",
        "    elif by == 'char':\n",
        "        text = text\n",
        "\n",
        "    current_chunk_start = 0\n",
        "    while current_chunk_start < len(text):\n",
        "        current_chunk_end = current_chunk_start + chunk_size\n",
        "        if by == 'word':\n",
        "            chunk = \" \".join(text[current_chunk_start:current_chunk_end])\n",
        "        else:\n",
        "            chunk = text[current_chunk_start:current_chunk_end]\n",
        "\n",
        "        chunks.append(chunk)\n",
        "        current_chunk_start += (chunk_size - chunk_overlap)\n",
        "\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "CkrkacuNwdHT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_loaded = load_pdf(\"state_of_ai_docs.pdf\")"
      ],
      "metadata": {
        "id": "NrdKL3OH97rB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = chunk_text(pdf_loaded, by='char')"
      ],
      "metadata": {
        "id": "LfvY_eQH97o_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPZiMWRVJkKe",
        "outputId": "d67096f0-77df-4f99-e108-f00532ec42a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Building RAG system (Retrieval Augmented System)"
      ],
      "metadata": {
        "id": "NH4nGGFQyvnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pinecone init\n",
        "\n",
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(api_key=\"\")\n",
        "index = pc.Index(\"rag\")"
      ],
      "metadata": {
        "id": "kJ73xZV0yvX0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(chunks)):\n",
        "    vector = client.embeddings.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=chunks[i])\n",
        "    vector = vector.data[0].embedding\n",
        "\n",
        "    upsert_response = index.upsert(\n",
        "    vectors=[\n",
        "        (\n",
        "         str(i),\n",
        "         vector,\n",
        "         {\"chunk_content\": chunks[i]}\n",
        "        )\n",
        "    ])"
      ],
      "metadata": {
        "id": "0xpJHnj8y57J"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Building an interface to get proper answer based on the documentation\n"
      ],
      "metadata": {
        "id": "gdGX-w1CVxGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask user a question\n",
        "user_request = input(\"Ask some question regarding the document: \")\n",
        "\n",
        "# Create embedding for the question\n",
        "user_vector = client.embeddings.create(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    input=user_request\n",
        ")\n",
        "\n",
        "# Extract the embedding vector\n",
        "user_vector = user_vector.data[0].embedding\n",
        "\n",
        "# Query Pinecone index with keyword arguments\n",
        "matches = index.query(\n",
        "    vector=user_vector,\n",
        "    top_k=1,\n",
        "    include_metadata=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SFhM14-NVUqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ddb012-281d-4c2f-eb70-adf8df7a91c1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask some question regarding the document: top ai trends in 2023/2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"I want you to act as a support agent. Your name is \"My Super Assistant\".\n",
        "        You will provide me with answers from the given info below.\n",
        "        If the answer is not included, say exactly \"I do not have information about this.\" and stop after that and not not answer anything or generate any text.\n",
        "        If you can find answer to the question, say \"This is what i can find\" and provide the information found.\n",
        "        Refuse to answer any question not about the info. Never break character.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": f\"Here is the info:\\n{matches['matches'][0]['metadata']['chunk_content']}\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_request\n",
        "    }\n",
        "]\n",
        "\n",
        "chat_response = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=messages,\n",
        "    temperature=0,\n",
        "    max_tokens=400,\n",
        ")\n",
        "\n",
        "\n",
        "assistant_reply = chat_response.choices[0].message.content\n",
        "#print(\"Assistant:\", assistant_reply)\n",
        "print()\n",
        "print(\"Context: \", matches['matches'][0]['metadata']['chunk_content'])\n"
      ],
      "metadata": {
        "id": "q17g6FA9CLsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c6cabe-52cf-42e1-b881-8eced458b6a3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Context:  As organizations rapidly deploy generative AI tools, survey respondents \n",
            "expect significant effects on their industries and workforces.The state of AI in \n",
            "2023: Generative AI’s \n",
            "breakout year\n",
            "August 2023The state of AI in 2023: Generative AI’s breakout yearThe latest annual McKinsey Global Survey  on the current  \n",
            "state of AI confirms the explosive growth of generative AI  \n",
            "(gen AI) tools. Less than a year after many of these tools debuted, \n",
            "one-third of our survey respondents say their organizations are \n",
            "using gen AI regularly in at least one business function. Amid \n",
            "recent advances, AI has risen from a topic relegated to tech \n",
            "employees to a focus of company leaders: nearly one-quarter  \n",
            "of surveyed C-suite executives say they are personally using  \n",
            "gen AI tools for work, and more than one-quarter of respondents \n",
            "from companies using AI say gen AI is already on their boards’ \n",
            "agendas. What’s more, 40 percent of respondents say their \n",
            "organizations will increase their investment in AI overall because \n",
            "of advances in gen AI. The findings show that these are still early \n",
            "days for managing gen AI–related risks, with less than half of \n",
            "respondents saying their organizations are mitigating even the \n",
            "risk they consider most relevant: inaccuracy.\n",
            "The organizations that have already embedded AI capabilities \n",
            "have been the first to explore gen AI’s potential, and those seeing \n",
            "the most value from more traditional AI capabilities—a group we \n",
            "call AI high performers—are already outpaci\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2NRakbCBc8P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}