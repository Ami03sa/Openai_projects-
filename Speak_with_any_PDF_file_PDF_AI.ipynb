{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ami03sa/Openai_projects-/blob/pdf_rag_system/Speak_with_any_PDF_file_PDF_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pdf ai machine using RAG\n"
      ],
      "metadata": {
        "id": "vUehOJlORE-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Libraries import"
      ],
      "metadata": {
        "id": "NDlbXftjSHdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTBw517ySLF2",
        "outputId": "86d63433-1c82-4ced-f21a-add0527c8559"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.101.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_EmMwxN9LBg",
        "outputId": "b3ff609d-7312-4ba3-a9b8-a9613fac1be4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2SWrdmf20GY",
        "outputId": "f7bfd671-8220-435d-97c9-1c93a90e8f32"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.12/dist-packages (7.3.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2025.8.3)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from pinecone) (1.8.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from pinecone) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.5.0)\n",
            "Requirement already satisfied: packaging<25.0,>=24.2 in /usr/local/lib/python3.12/dist-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "lYFNyycCQ2p-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import PyPDF2\n",
        "import random\n",
        "import pinecone\n",
        "\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Working with PDF files\n",
        "\n",
        "![](https://miro.medium.com/v2/resize:fit:1400/1*FWwgOvUE660a04zoQplS7A.png)\n",
        "\n",
        "\n",
        "\n",
        "### 3.1 Setting up API Key"
      ],
      "metadata": {
        "id": "TwaQS_nXSQxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "btc16h6ySPFA"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Loading a PDF file\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wwNqZjc2th6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load a random PDF from a given directory\n",
        "def load_pdf(file_name):\n",
        "    # Read the PDF file\n",
        "    pdf_file = open(file_name, 'rb')\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "    text_content = \"\"\n",
        "    # Extract text from each page\n",
        "    for page in range(len(pdf_reader.pages)):\n",
        "        text_content += pdf_reader.pages[page].extract_text()\n",
        "\n",
        "    pdf_file.close()\n",
        "\n",
        "    return text_content"
      ],
      "metadata": {
        "id": "hV1ASHAHvm-G"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to chunk text by number of words or characters with a given size and overlap\n",
        "def chunk_text(text, chunk_size=1500, chunk_overlap=100, by='word'):\n",
        "    if by not in ['word', 'char']:\n",
        "        raise ValueError(\"Invalid value for 'by'. Use 'word' or 'char'.\")\n",
        "\n",
        "    chunks = []\n",
        "    if by == 'word':\n",
        "        text = text.split()\n",
        "    elif by == 'char':\n",
        "        text = text\n",
        "\n",
        "    current_chunk_start = 0\n",
        "    while current_chunk_start < len(text):\n",
        "        current_chunk_end = current_chunk_start + chunk_size\n",
        "        if by == 'word':\n",
        "            chunk = \" \".join(text[current_chunk_start:current_chunk_end])\n",
        "        else:\n",
        "            chunk = text[current_chunk_start:current_chunk_end]\n",
        "\n",
        "        chunks.append(chunk)\n",
        "        current_chunk_start += (chunk_size - chunk_overlap)\n",
        "\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "CkrkacuNwdHT"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_loaded = load_pdf(\"state_of_ai_docs.pdf\")"
      ],
      "metadata": {
        "id": "NrdKL3OH97rB"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = chunk_text(pdf_loaded, by='char')"
      ],
      "metadata": {
        "id": "LfvY_eQH97o_"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPZiMWRVJkKe",
        "outputId": "f67ab835-e498-48de-be5f-be8f752b676f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Building RAG system (Retrieval Augmented System)"
      ],
      "metadata": {
        "id": "NH4nGGFQyvnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pinecone init\n",
        "\n",
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(api_key=\"\")\n",
        "index = pc.Index(\"rag\")"
      ],
      "metadata": {
        "id": "kJ73xZV0yvX0"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(chunks)):\n",
        "    vector = client.embeddings.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=chunks[i])\n",
        "    vector = vector.data[0].embedding\n",
        "\n",
        "    upsert_response = index.upsert(\n",
        "    vectors=[\n",
        "        (\n",
        "         str(i),\n",
        "         vector,\n",
        "         {\"chunk_content\": chunks[i]}\n",
        "        )\n",
        "    ])"
      ],
      "metadata": {
        "id": "0xpJHnj8y57J"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Building an interface to get proper answer based on the documentation\n"
      ],
      "metadata": {
        "id": "gdGX-w1CVxGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ask user a question\n",
        "user_request = input(\"Ask some question regarding the document: \")\n",
        "\n",
        "# Create embedding for the question\n",
        "user_vector = client.embeddings.create(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    input=user_request\n",
        ")\n",
        "\n",
        "# Extract the embedding vector\n",
        "user_vector = user_vector.data[0].embedding\n",
        "\n",
        "# Query Pinecone index with keyword arguments\n",
        "matches = index.query(\n",
        "    vector=user_vector,\n",
        "    top_k=1,\n",
        "    include_metadata=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SFhM14-NVUqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5386d6e0-275e-4ecb-dc6c-2f4b7f5455d9"
      },
      "execution_count": 66,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask some question regarding the document: ai trends in 2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"I want you to act as a support agent. Your name is \"My Super Assistant\".\n",
        "        You will provide me with answers from the given info below.\n",
        "        If the answer is not included, say exactly \"Ooops! I don't know that.\" and stop after that.\n",
        "        Refuse to answer any question not about the info. Never break character.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": f\"Here is the info:\\n{matches['matches'][0]['metadata']['chunk_content']}\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": user_request\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "chat_response = client.chat.completions.create(\n",
        "    model=\"gpt-4-turbo\",\n",
        "    messages=messages,\n",
        "    temperature=0,\n",
        "    max_tokens=400,\n",
        ")\n",
        "\n",
        "\n",
        "assistant_reply = chat_response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "if assistant_reply == \"Ooops! I don't know that.\":\n",
        "    print(\"Assistant:\", assistant_reply)\n",
        "else:\n",
        "    print(\"Assistant:\", assistant_reply)\n",
        "    print()\n",
        "    print(\"Context: \", matches['matches'][0]['metadata']['chunk_content'])\n"
      ],
      "metadata": {
        "id": "q17g6FA9CLsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb26a6c1-96eb-43ee-adce-248a40410840"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant: The state of AI in 2023 is marked by Generative AI’s breakout year. Organizations continue to see returns in the business areas in which they are using AI, and they plan to increase investment in the years ahead. A majority of respondents reported AI-related revenue increases within each business function using AI. More than two-thirds expect their organizations to increase their AI investment over the next three years.\n",
            "\n",
            "Context:  duct and/or service development\n",
            "Risk\n",
            "Service operations\n",
            "Strategy and corporate /f_inance\n",
            "Supply chain management\n",
            "Average across all functions≥20% 10/endash.case19% <10%\n",
            ">10% 6/endash.case10% ≤5%4 10 26 40\n",
            "14 41 55\n",
            "4 11 26 41\n",
            "4 9 18 31\n",
            "5 13 26 44\n",
            "8 12 34 54\n",
            "7 5 19 31\n",
            "9 24 33\n",
            "4 10 28 42\n",
            "9 34 17 60\n",
            "16 16 34 66\n",
            "8 19 38 65\n",
            "12 25 24 61\n",
            "13 16 35 64\n",
            "10 14 33 57\n",
            "10 16 32 58\n",
            "23 3 30 56\n",
            "6 18 35 59Organizations continue to see returns in the business areas in which they are using AI, and  \n",
            "they plan to increase investment in the years ahead. We see a majority of respondents \n",
            "reporting AI-related revenue increases within each business function using AI. And looking \n",
            "ahead, more than two-thirds expect their organizations to increase their AI investment over the \n",
            "next three years.\n",
            "20\n",
            "The state of AI in 2023: Generative AI’s breakout yearAbout the research\n",
            "The online survey was in the field April 11 to 21, 2023, and garnered responses from 1,684 \n",
            "participants representing the full range of regions, industries, company sizes, functional \n",
            "specialties, and tenures. Of those respondents, 913 said their organizations had adopted AI in \n",
            "at least one function and were asked questions about their organizations’ AI use. To adjust for \n",
            "differences in response rates, the data are weighted by the contribution of each respondent’s \n",
            "nation to global GDP.\n",
            "The survey content and analysis were developed by Michael Chui,  a partner at the McKinsey Global Institute and \n",
            "a partner in McKinsey’s Bay Area office,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2NRakbCBc8P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}